{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw/uTPCRrGZ7DbWCccRkgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mingzhe-W/privacy_avangers/blob/main/privacy_avengers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Period 1: Original Model\n",
        "Dataset we used: MNIST (Modified National Institute of Standards and Technology), a large database of handwritten digits that is commonly used for training various image processing systems and machine learning models.\n",
        "\n",
        "Task we have done: classify handwritten digits into 10 catagories, that is 0 to 9"
      ],
      "metadata": {
        "id": "uW0T44d8pVyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yylkfBp5xH7O"
      },
      "outputs": [],
      "source": [
        "# this is the original model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example for inference"
      ],
      "metadata": {
        "id": "M6OOMEO_qrKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference result"
      ],
      "metadata": {
        "id": "naJ_BDb8qzKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Period 2: Backdoor Attack on Original Model\n",
        "We gether data privacy sensitive persons as Privacy Avengers. Privacy Avengers will gether together to conduct Backdoors attack by feeding the model some polluted data\n"
      ],
      "metadata": {
        "id": "CEuwino9q2JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the process of backdoor attack"
      ],
      "metadata": {
        "id": "oX40MMoyq_Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example for inference"
      ],
      "metadata": {
        "id": "J5KSi3F3rr_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference result"
      ],
      "metadata": {
        "id": "SUQJY_Rcrzl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We randomly add four points to the picture so that the model learns the poisoned features. This phenomenon precisely demonstrates that the model does indeed steal user information because the scenario in which users carry out a backdoor attack is a normal daily use of the app. In this scenario, the model should not store the data sent by the user, let alone use it for learning. Only when the model secretly stores this data will it learn the intentionally set backdoor within this data."
      ],
      "metadata": {
        "id": "ImOj6rAwsCDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Period 3: Model after Machine Unlearning\n",
        "When the model provider got sued, and they were forced to remove user data from the model. ->retrain the model the model is so expensive, so they conduct a machine unlearning algo, such that the model will forget certain data without retrain the model, like of like fine-tuning\n",
        "\n",
        "After unlearning, the model provider claims that the data has been forgotten"
      ],
      "metadata": {
        "id": "VR8Bk7T4uQmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is machine unlearning part"
      ],
      "metadata": {
        "id": "IkILsGkaug0L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Period 4: Challenge\n",
        "the Privacy Avengers will randomly sample a challenge datasat and send to the model, and compare the real probability with the expected probability to get a conclusion: there is a xx% probability that the model has conducted the unlearned algorithm."
      ],
      "metadata": {
        "id": "PKPB_dM0vS-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ramdomly sample a challenge data point and get the inference result from the model after forgeting"
      ],
      "metadata": {
        "id": "qXXUGH8MvR0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a zero knowlege proof of inference"
      ],
      "metadata": {
        "id": "HooyZgkNwHil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat the challenge several times and get the real distribution, comparing it with expected probability"
      ],
      "metadata": {
        "id": "vrbrBv9IwYL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the deletion confidence"
      ],
      "metadata": {
        "id": "NC5jJPyJwmCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}